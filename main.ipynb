{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from torch.nn.functional import one_hot\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import one_hot, softmax, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \":heart:\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_emoji(target_label):\n",
    "    assert type(target_label) == str\n",
    "    emoji_unicode = emoji_dictionary.get(target_label)\n",
    "    return emoji.emojize(emoji_unicode, use_aliases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_X_Y(file_path):\n",
    "    data = pd.read_csv(file_path, error_bad_lines=False)\n",
    "    # In case of prior manilulations.    \n",
    "    if 'Unnamed: 2' in data.columns or 'Unnamed: 3' in data.columns:\n",
    "        data = data.drop(columns=['Unnamed: 2', 'Unnamed: 3'])\n",
    "    \n",
    "    data.columns = ['phrase', 'label']\n",
    "    X = data.get('phrase')\n",
    "    Y = data.get('label')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = extract_X_Y('./data/train_emoji.csv')\n",
    "X_test, Y_test = extract_X_Y('./data/test_emoji.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_Y_train = one_hot(Y_train.values, 5)\n",
    "oh_Y_test = one_hot(Y_test.values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (131,)\n",
      "Y_train Shape: (131, 5)\n",
      "X_test Shape: (55,)\n",
      "Y_test Shape: (55, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train Shape:\", X_train.shape)\n",
    "print(\"Y_train Shape:\", oh_Y_train.shape)\n",
    "print(\"X_test Shape:\", X_test.shape)\n",
    "print(\"Y_test Shape:\", oh_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think I will end up alone ðŸ˜ž\n",
      "Label index 3 is one-hot encoded as: [0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(X_train[idx], label_to_emoji(str(Y_train[idx])))\n",
    "print(\"Label index %d is one-hot encoded as:\" % Y_train[idx], oh_Y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Emojifier V-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Emojifier V-1](./images/Emojifier-V1.png)\n",
    "\n",
    "#### Inputs and outputs\n",
    "* The input of the model is a string corresponding to a sentence (e.g. \"I love you). \n",
    "* The output will be a probability vector of shape (1,5), (there are 5 emojis to choose from).\n",
    "* The (1,5) probability vector is passed to an argmax layer, which extracts the index of the emoji with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Word Vector\n",
    "\n",
    "[GloVe](https://nlp.stanford.edu/projects/glove/) is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read GloVe File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(file_path):\n",
    "    print(\"Loading Glove Model..\")\n",
    "    f = open(file_path,'r', errors = 'ignore', encoding='utf8')\n",
    "    gloveModel = {}\n",
    "    words = set()\n",
    "    for line in f:\n",
    "        try:\n",
    "            splitLines = line.split()\n",
    "            word = splitLines[0]\n",
    "            words.add(word)\n",
    "            wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "            gloveModel[word] = wordEmbedding\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    i = 1\n",
    "    words_to_index = {}\n",
    "    index_to_words = {}\n",
    "    for w in sorted(words):\n",
    "        words_to_index[w] = i\n",
    "        index_to_words[i] = w\n",
    "        i = i + 1\n",
    "    print(len(gloveModel),\"words loaded!\")\n",
    "    return words_to_index, index_to_words, gloveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model..\n",
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs('./GloVe/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word_to_vector map Shape: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Word_to_vector map Shape:\", len(word_to_vec_map.get('food')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'food' has index 151204 in GloVe vector.\n",
      "Index 250000 belong to the word 'morpheus'.\n"
     ]
    }
   ],
   "source": [
    "word = 'food'\n",
    "word_idx = words_to_index.get(word)\n",
    "\n",
    "print(\"Word '%s' has index %d in GloVe vector.\" % (word, word_idx))\n",
    "\n",
    "idx = 250000\n",
    "word = index_to_words.get(idx)\n",
    "print(\"Index %d belong to the word '%s'.\" % (idx, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vector):\n",
    "    words = (sentence.lower()).split()\n",
    "    avg = np.zeros((50,))\n",
    "    total = 0\n",
    "    for w in words:\n",
    "        total += word_to_vec_map[w]\n",
    "    avg = total / float(len(words))\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg = \n",
      " [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \\n\", avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the V1 model\n",
    "\n",
    "Now that the sentences's average function is created and GloVe word vector is loaded, its time to construct the model. In this case the model uses cross-entropy cost function:\n",
    "\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Y_{oh,k}^{(i)} * log(a^{(i)}_k)$$\n",
    "\n",
    "And the gradients are computed as:\n",
    "\n",
    "$$ \\frac{d}{dx}Z = a^{(i)} - Y_{oh}^{(i)}$$\n",
    "\n",
    "$$ \\frac{d}{dx}W = \\frac{d}{dx}Z{(i)} . avg^{(i)}$$\n",
    "\n",
    "$$ \\frac{d}{dx}b = \\frac{d}{dx}Z^{(i)}$$\n",
    "\n",
    "***Note:*** The $Y_{oh}$ denotes one-hoted $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vector_map, lr=0.01, epochs=400):\n",
    "\n",
    "    m = X.shape[0]                          \n",
    "    n_y = 5                                  \n",
    "    n_h = 50\n",
    "    \n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    Y_oh = one_hot(Y, n_y) \n",
    "    \n",
    "    for t in range(epochs):\n",
    "        for i in range(m):\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "            \n",
    "            z = np.matmul(W, avg) + b\n",
    "            a = softmax(z)\n",
    "            \n",
    "            cost = -(np.matmul(Y_oh[i], np.log(a)))\n",
    "            \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            W = W - lr * dW\n",
    "            b = b - lr * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if str(type(X_train)) != \"<class 'numpy.ndarray'>\":\n",
    "    X_train = X_train.values\n",
    "    Y_train = Y_train.values\n",
    "    X_test = X_test.values\n",
    "    Y_test = Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9938412874344404\n",
      "Accuracy: 0.31297709923664124\n",
      "Epoch: 100 --- cost = 0.08066259933502952\n",
      "Accuracy: 0.9312977099236641\n",
      "Epoch: 200 --- cost = 0.04833138260591153\n",
      "Accuracy: 0.9465648854961832\n",
      "Epoch: 300 --- cost = 0.03840423410146641\n",
      "Accuracy: 0.9694656488549618\n",
      "[[2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9770992366412213\n",
      "Test set:\n",
      "Accuracy: 0.8545454545454545\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
